{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BSEU-Misal/SWUs-for-Cervical-Spinal-Cord/blob/main/SwinUnets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08eccd5e-208b-40b7-b205-f37bb8ea7874",
      "metadata": {
        "id": "08eccd5e-208b-40b7-b205-f37bb8ea7874"
      },
      "source": [
        "Model SWU1: Encoder = Swin Transformer, Decoder = CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bebf16c9-6aff-4d35-a42e-d9680c2412e5",
      "metadata": {
        "id": "bebf16c9-6aff-4d35-a42e-d9680c2412e5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import timm\n",
        "\n",
        "class DecoderBlockCNN(nn.Module):\n",
        "    def __init__(self, in_ch, skip_ch, out_ch):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_ch + skip_ch, out_ch, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x, skip):\n",
        "        x = F.interpolate(x, size=skip.shape[2:], mode='bilinear', align_corners=False)\n",
        "        x = torch.cat([x, skip], dim=1)\n",
        "        return self.conv(x)\n",
        "\n",
        "class SwinEncoder_CNNDecoder_UNet(nn.Module):\n",
        "    def __init__(self, img_size=384, num_classes=1):\n",
        "        super().__init__()\n",
        "        self.img_size = img_size\n",
        "        self.num_classes = num_classes\n",
        "        self.backbone = timm.create_model(\n",
        "            'swin_base_patch4_window12_384',\n",
        "            pretrained=True,\n",
        "            features_only=True\n",
        "        )\n",
        "        chs = self.backbone.feature_info.channels()  # [96,192,384,768]\n",
        "\n",
        "        self.dec4 = DecoderBlockCNN(chs[3], chs[2], 512)\n",
        "        self.dec3 = DecoderBlockCNN(512, chs[1], 256)\n",
        "        self.dec2 = DecoderBlockCNN(256, chs[0], 128)\n",
        "        self.dec1 = DecoderBlockCNN(128, 64, 64)  # skip_ch = 64 (√∂rnek)\n",
        "        self.final_conv = nn.Conv2d(64, num_classes, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        feats = self.backbone(x)\n",
        "        feats = [f.permute(0, 3, 1, 2).contiguous() for f in feats]  # [B,H,W,C] ‚Üí [B,C,H,W]\n",
        "\n",
        "        f1, f2, f3, f4 = feats\n",
        "        d4 = self.dec4(f4, f3)\n",
        "        d3 = self.dec3(d4, f2)\n",
        "        d2 = self.dec2(d3, f1)\n",
        "        d1 = self.dec1(d2, f1)\n",
        "        out = self.final_conv(d1)\n",
        "\n",
        "\n",
        "        out = F.interpolate(out, size=x.shape[2:], mode='bilinear', align_corners=False)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YkGS5VsP3Adc",
      "metadata": {
        "id": "YkGS5VsP3Adc"
      },
      "source": [
        "Model SWU2: Encoder = CNN, Decoder = Swin Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9c2e0b4-0786-4b78-b2f4-a684e66afa4b",
      "metadata": {
        "id": "d9c2e0b4-0786-4b78-b2f4-a684e66afa4b"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import timm\n",
        "from timm.models.swin_transformer import SwinTransformerBlock\n",
        "\n",
        "class CNNEncoderBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_ch, out_ch, 3, stride=2, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(out_ch)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(out_ch)\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.relu(self.bn2(self.conv2(x)))\n",
        "        return x\n",
        "\n",
        "class SwinDecoderBlock(nn.Module):\n",
        "    def __init__(self, dim, skip_dim, resolution, num_heads, window_size=7):\n",
        "        super().__init__()\n",
        "        self.up = nn.ConvTranspose2d(dim, dim//2, kernel_size=2, stride=2)\n",
        "        self.norm = nn.LayerNorm((dim//2 + skip_dim))\n",
        "        self.linear = nn.Linear(dim//2 + skip_dim, dim//2)\n",
        "        self.swin1 = SwinTransformerBlock(dim=dim//2, input_resolution=resolution, num_heads=num_heads, window_size=window_size)\n",
        "        self.swin2 = SwinTransformerBlock(dim=dim//2, input_resolution=resolution, num_heads=num_heads, window_size=window_size, shift_size=window_size//2)\n",
        "\n",
        "    def forward(self, x, skip):\n",
        "        x = self.up(x)\n",
        "        x = torch.cat([x, skip], dim=1)\n",
        "        B,C,H,W = x.shape\n",
        "        x = x.permute(0,2,3,1).contiguous()\n",
        "        x = self.norm(x)\n",
        "        x = self.linear(x)\n",
        "        x = self.swin1(x)\n",
        "        x = self.swin2(x)\n",
        "        return x.permute(0,3,1,2).contiguous()\n",
        "\n",
        "class CNNEncoder_SwinDecoder_UNet(nn.Module):\n",
        "    def __init__(self, img_size=384, num_classes=1):\n",
        "        super().__init__()\n",
        "        self.img_size = img_size\n",
        "        self.enc1 = CNNEncoderBlock(3,64)\n",
        "        self.enc2 = CNNEncoderBlock(64,128)\n",
        "        self.enc3 = CNNEncoderBlock(128,256)\n",
        "        self.enc4 = CNNEncoderBlock(256,512)\n",
        "        resolution = img_size // 16\n",
        "\n",
        "        self.dec4 = SwinDecoderBlock(512,256,(resolution, resolution), num_heads=8)\n",
        "        self.dec3 = SwinDecoderBlock(256,128,(resolution*2, resolution*2), num_heads=4)\n",
        "        self.dec2 = SwinDecoderBlock(128,64,(resolution*4, resolution*4), num_heads=2)\n",
        "        self.dec1 = nn.Sequential(\n",
        "            nn.Conv2d(64,64,3,padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64,64,3,padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "        self.final_conv = nn.Conv2d(64, num_classes, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        e1 = self.enc1(x)\n",
        "        e2 = self.enc2(e1)\n",
        "        e3 = self.enc3(e2)\n",
        "        e4 = self.enc4(e3)\n",
        "        d4 = self.dec4(e4, e3)\n",
        "        d3 = self.dec3(d4, e2)\n",
        "        d2 = self.dec2(d3, e1)\n",
        "        d1 = self.dec1(d2)\n",
        "        out = self.final_conv(d1)\n",
        "        return F.interpolate(out, size=(self.img_size, self.img_size),\n",
        "                             mode='bilinear', align_corners=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RlMz4IDm3DXU",
      "metadata": {
        "id": "RlMz4IDm3DXU"
      },
      "source": [
        "Model SWU3: Full Swin‚ÄëUNet (Encoder + Decoder = Swin Transformer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8575044-8d23-44ba-a90f-08a08446702f",
      "metadata": {
        "id": "f8575044-8d23-44ba-a90f-08a08446702f"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import timm\n",
        "from timm.models.swin_transformer import SwinTransformerBlock\n",
        "\n",
        "class SwinDecoderTransformerBlock(nn.Module):\n",
        "    def __init__(self, dim, skip_dim, resolution, num_heads, window_size=7):\n",
        "        super().__init__()\n",
        "        self.up = nn.ConvTranspose2d(dim, dim//2, kernel_size=2, stride=2)\n",
        "        self.norm = nn.LayerNorm((dim//2 + skip_dim))\n",
        "        self.linear = nn.Linear(dim//2 + skip_dim, dim//2)\n",
        "        self.swin1 = SwinTransformerBlock(dim=dim//2, input_resolution=resolution, num_heads=num_heads, window_size=window_size)\n",
        "        self.swin2 = SwinTransformerBlock(dim=dim//2, input_resolution=resolution, num_heads=num_heads, window_size=window_size, shift_size=window_size//2)\n",
        "\n",
        "    def forward(self, x, skip):\n",
        "        x = self.up(x)\n",
        "        x = torch.cat([x, skip], dim=1)\n",
        "        B,C,H,W = x.shape\n",
        "        x = x.permute(0,2,3,1).contiguous()\n",
        "        x = self.norm(x)\n",
        "        x = self.linear(x)\n",
        "        x = self.swin1(x)\n",
        "        x = self.swin2(x)\n",
        "        return x.permute(0,3,1,2).contiguous()\n",
        "\n",
        "class SwinUNetFull(nn.Module):\n",
        "    def __init__(self, img_size=384, num_classes=1):\n",
        "        super().__init__()\n",
        "        self.img_size = img_size\n",
        "        self.backbone = timm.create_model(\n",
        "            'swin_base_patch4_window12_384',\n",
        "            pretrained=True,\n",
        "            features_only=True\n",
        "        )\n",
        "        chs = self.backbone.feature_info.channels()\n",
        "        resolution = img_size // 32\n",
        "\n",
        "        self.dec4 = SwinDecoderTransformerBlock(chs[3], chs[2], (resolution*2, resolution*2), num_heads=12)\n",
        "        self.dec3 = SwinDecoderTransformerBlock(chs[2], chs[1], (resolution*4, resolution*4), num_heads=6)\n",
        "        self.dec2 = SwinDecoderTransformerBlock(chs[1], chs[0], (resolution*8, resolution*8), num_heads=3)\n",
        "        self.final_conv = nn.Sequential(\n",
        "            nn.Conv2d(chs[0]//2, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, num_classes, kernel_size=1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        feats = self.backbone(x)\n",
        "        feats = [f.permute(0,3,1,2).contiguous() for f in feats]\n",
        "        f1,f2,f3,f4 = feats\n",
        "        d4 = self.dec4(f4, f3)\n",
        "        d3 = self.dec3(d4, f2)\n",
        "        d2 = self.dec2(d3, f1)\n",
        "        out = self.final_conv(d2)\n",
        "        return F.interpolate(out, size=(self.img_size, self.img_size),\n",
        "                             mode='bilinear', align_corners=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59bb16f0-5b4e-4cc7-b1d3-17de25d8a7ef",
      "metadata": {
        "id": "59bb16f0-5b4e-4cc7-b1d3-17de25d8a7ef"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# ========================\n",
        "# Parametreler\n",
        "# ========================\n",
        "SIZE = 384\n",
        "BATCH_SIZE = 8\n",
        "\n",
        "\n",
        "train_image_dir =\"/mnt/data/sagSpinMS/train/Images/\"\n",
        "train_mask_dir =\"/mnt/data/sagSpinMS/train/Maskes/\"\n",
        "\n",
        "\n",
        "test_image_dir = \"/mnt/data/sagSpinMS/test/Images/\"\n",
        "test_mask_dir = \"/mnt/data/sagSpinMS/test/Maskes/\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ========================\n",
        "# G√∂r√ºnt√º Y√ºkleyici Fonksiyon\n",
        "# ========================\n",
        "def load_image(path, size, is_mask=False):\n",
        "    flag = cv2.IMREAD_GRAYSCALE if is_mask else cv2.IMREAD_COLOR\n",
        "    image = cv2.imread(path, flag)\n",
        "\n",
        "    if image is None:\n",
        "        print(f\"Uyarƒ±: Dosya okunamadƒ±: {path}\")\n",
        "        return None\n",
        "\n",
        "    if not is_mask:\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        image = Image.fromarray(image).resize((size, size), resample=Image.BILINEAR)\n",
        "        return np.array(image)\n",
        "    else:\n",
        "        mask = Image.fromarray(image).resize((size, size), resample=Image.NEAREST)\n",
        "        mask = np.array(mask)\n",
        "        mask = (mask > 127).astype(np.uint8)\n",
        "        return mask\n",
        "\n",
        "# ========================\n",
        "# Dataset Listesini Y√ºkle\n",
        "# ========================\n",
        "def load_dataset(image_dir, mask_dir, size):\n",
        "    image_names = sorted([f for f in os.listdir(image_dir) if f.lower().endswith(\".png\")])\n",
        "    mask_names = sorted([f for f in os.listdir(mask_dir) if f.lower().endswith(\".png\")])\n",
        "\n",
        "    assert len(image_names) == len(mask_names), \"G√∂r√ºnt√º ve maske sayƒ±sƒ± e≈üle≈ümiyor!\"\n",
        "\n",
        "    images, masks = [], []\n",
        "\n",
        "    for img_name, mask_name in zip(image_names, mask_names):\n",
        "        img_path = os.path.join(image_dir, img_name)\n",
        "        mask_path = os.path.join(mask_dir, mask_name)\n",
        "\n",
        "        image = load_image(img_path, size, is_mask=False)\n",
        "        mask = load_image(mask_path, size, is_mask=True)\n",
        "\n",
        "        if image is not None and mask is not None:\n",
        "            images.append(image)\n",
        "            masks.append(mask)\n",
        "\n",
        "    print(f\"Toplam {len(images)} √∂rnek y√ºklendi.\")\n",
        "    return images, masks\n",
        "\n",
        "# ========================\n",
        "# Dataset Sƒ±nƒ±fƒ±\n",
        "# ========================\n",
        "class SegmentationDataset(Dataset):\n",
        "    def __init__(self, images, masks, transform=None):\n",
        "        self.images = images\n",
        "        self.masks = masks\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        mask = self.masks[idx]\n",
        "\n",
        "\n",
        "        image = torch.tensor(image / 255.0, dtype=torch.float32).permute(2, 0, 1)  # [3, H, W]\n",
        "        mask = torch.tensor(mask, dtype=torch.float32).unsqueeze(0)               # [1, H, W]\n",
        "\n",
        "\n",
        "        if self.transform:\n",
        "            augmented = self.transform(image=image.permute(1, 2, 0).numpy(), mask=mask.squeeze(0).numpy())\n",
        "            image = torch.tensor(augmented['image']).permute(2, 0, 1).float()\n",
        "            mask = torch.tensor(augmented['mask']).unsqueeze(0).float()\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "# ========================\n",
        "# Eƒüitim ve Test Verilerini Y√ºkle\n",
        "# ========================\n",
        "train_images, train_masks = load_dataset(train_image_dir, train_mask_dir, SIZE)\n",
        "test_images, test_masks = load_dataset(test_image_dir, test_mask_dir, SIZE)\n",
        "\n",
        "train_dataset = SegmentationDataset(train_images, train_masks)\n",
        "test_dataset = SegmentationDataset(test_images, test_masks)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "print(f\"[‚úì] Train loader hazƒ±r ‚Üí {len(train_dataset)} √∂rnek\")\n",
        "print(f\"[‚úì] Test loader hazƒ±r  ‚Üí {len(test_dataset)} √∂rnek\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e025c225-10e3-411e-9643-8c33dcafc63e",
      "metadata": {
        "id": "e025c225-10e3-411e-9643-8c33dcafc63e"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import pandas as pd\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# ==================================================\n",
        "# 1. Helper: Metrics hesaplama (accuracy, dice, iou)\n",
        "# ==================================================\n",
        "def calculate_metrics(outputs, masks, threshold=0.5):\n",
        "    with torch.no_grad():\n",
        "        probs = torch.sigmoid(outputs)\n",
        "        preds = (probs > threshold).float()\n",
        "\n",
        "        correct = (preds == masks).sum().item()\n",
        "        total = masks.numel()\n",
        "\n",
        "        smooth = 1e-6\n",
        "        intersection = (preds * masks).sum(dim=(1,2,3))\n",
        "        union = preds.sum(dim=(1,2,3)) + masks.sum(dim=(1,2,3))\n",
        "\n",
        "        dice = ((2 * intersection + smooth) / (union + smooth)).mean().item()\n",
        "\n",
        "        intersection_iou = (preds * masks).sum(dim=(1,2,3))\n",
        "        union_iou = (preds + masks - preds * masks).sum(dim=(1,2,3))\n",
        "        iou = ((intersection_iou + smooth) / (union_iou + smooth)).mean().item()\n",
        "\n",
        "    return correct, total, dice, iou\n",
        "\n",
        "# ========================\n",
        "# 2. Validation fonksiyonu\n",
        "# ========================\n",
        "def validate(model, val_loader, criterion, device):\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    correct_preds = 0\n",
        "    total_preds = 0\n",
        "    dice_scores = []\n",
        "    iou_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, masks in val_loader:\n",
        "            images = images.to(device)\n",
        "            masks = masks.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, masks)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            c, t, dice, iou = calculate_metrics(outputs, masks)\n",
        "            correct_preds += c\n",
        "            total_preds += t\n",
        "            dice_scores.append(dice)\n",
        "            iou_scores.append(iou)\n",
        "\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "    avg_val_acc = correct_preds / total_preds * 100\n",
        "    avg_dice = np.mean(dice_scores)\n",
        "    avg_iou = np.mean(iou_scores)\n",
        "\n",
        "    return avg_val_loss, avg_val_acc, avg_dice, avg_iou\n",
        "\n",
        "# ========================\n",
        "# 3. Eƒüitim parametreleri\n",
        "# ========================\n",
        "batch_size = 8\n",
        "num_epochs = 100\n",
        "learning_rate = 1e-4\n",
        "SIZE = 384\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ========================\n",
        "# 4. Model, Loss, Optimizer\n",
        "# ========================\n",
        "model = decoSwin(img_size=SIZE, num_classes=1).to(device)\n",
        "criterion = ComboLoss(bce_weight=0.5, dice_weight=0.5)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# ========================\n",
        "# 5. Eƒüitim i√ßin kayƒ±tlar\n",
        "# ========================\n",
        "history = {\n",
        "    \"epoch\": [],\n",
        "    \"train_loss\": [],\n",
        "    \"train_acc\": [],\n",
        "    \"val_loss\": [],\n",
        "    \"val_acc\": [],\n",
        "    \"val_dice\": [],\n",
        "    \"val_iou\": [],\n",
        "    \"epoch_time_sec\": []\n",
        "}\n",
        "\n",
        "best_val_loss = float('inf')\n",
        "best_epoch = -1\n",
        "\n",
        "# ========================\n",
        "# 6. Eƒüitim d√∂ng√ºs√º (T√ºm s√ºre √∂l√ß√ºm√º dahil)\n",
        "# ========================\n",
        "total_start_time = time.time()  # ‚è±Ô∏è Toplam s√ºre ba≈ülangƒ±cƒ±\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    epoch_start_time = time.time()\n",
        "\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct_preds = 0\n",
        "    total_preds = 0\n",
        "\n",
        "    loop = tqdm(train_loader, desc=f\"Epoch [{epoch+1}/{num_epochs}]\", leave=False)\n",
        "\n",
        "    for images, masks in loop:\n",
        "        images = images.to(device)\n",
        "        masks = masks.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, masks)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        c, t, _, _ = calculate_metrics(outputs, masks)\n",
        "        correct_preds += c\n",
        "        total_preds += t\n",
        "\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    epoch_train_loss = running_loss / len(train_loader)\n",
        "    epoch_train_acc = correct_preds / total_preds * 100\n",
        "\n",
        "    epoch_val_loss, epoch_val_acc, epoch_val_dice, epoch_val_iou = validate(model, test_loader, criterion, device)\n",
        "\n",
        "    epoch_end_time = time.time()\n",
        "    epoch_duration = epoch_end_time - epoch_start_time\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} - \"\n",
        "          f\"Train Loss: {epoch_train_loss:.4f}, Train Acc: {epoch_train_acc:.2f}% | \"\n",
        "          f\"Val Loss: {epoch_val_loss:.4f}, Val Acc: {epoch_val_acc:.2f}%, \"\n",
        "          f\"Dice: {epoch_val_dice:.4f}, IoU: {epoch_val_iou:.4f}, \"\n",
        "          f\"Time: {epoch_duration:.1f}s\")\n",
        "\n",
        "    # En iyi modeli kaydet\n",
        "    if epoch_val_loss < best_val_loss:\n",
        "        best_val_loss = epoch_val_loss\n",
        "        best_epoch = epoch + 1\n",
        "        torch.save(model.state_dict(), \"model.pth\")\n",
        "        print(f\"‚úÖ Model kaydedildi. (Epoch {best_epoch}, Val Loss: {best_val_loss:.4f})\")\n",
        "\n",
        "    # History update\n",
        "    history[\"epoch\"].append(epoch + 1)\n",
        "    history[\"train_loss\"].append(epoch_train_loss)\n",
        "    history[\"train_acc\"].append(epoch_train_acc)\n",
        "    history[\"val_loss\"].append(epoch_val_loss)\n",
        "    history[\"val_acc\"].append(epoch_val_acc)\n",
        "    history[\"val_dice\"].append(epoch_val_dice)\n",
        "    history[\"val_iou\"].append(epoch_val_iou)\n",
        "    history[\"epoch_time_sec\"].append(epoch_duration)\n",
        "\n",
        "# T√ºm eƒüitim s√ºresi\n",
        "total_end_time = time.time()\n",
        "total_training_time = total_end_time - total_start_time\n",
        "print(f\"\\n‚è±Ô∏è Toplam Eƒüitim S√ºresi: {total_training_time:.1f} saniye\")\n",
        "\n",
        "# ========================\n",
        "# 7. Sonu√ßlarƒ± CSV dosyasƒ±na kaydet\n",
        "# ========================\n",
        "df = pd.DataFrame(history)\n",
        "df.to_csv(\"deco-swin_training.csv\", index=False)\n",
        "print(\"üìÅ Eƒüitim ge√ßmi≈üi 'model_training.csv' olarak kaydedildi.\")\n",
        "\n",
        "# ========================\n",
        "# 8. Sonu√ßlarƒ± HDF5 dosyasƒ±na kaydet\n",
        "# ========================\n",
        "with h5py.File(\"model.h5\", \"w\") as hf:\n",
        "    for key, values in history.items():\n",
        "        hf.create_dataset(key, data=np.array(values))\n",
        "    hf.attrs[\"total_training_time_sec\"] = total_training_time\n",
        "    hf.attrs[\"best_epoch\"] = best_epoch\n",
        "    hf.attrs[\"best_val_loss\"] = best_val_loss\n",
        "\n",
        "print(\"üìÅ Eƒüitim ge√ßmi≈üi 'model.h5' olarak kaydedildi.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52670c26-2135-40ff-81b8-b113010403ec",
      "metadata": {
        "id": "52670c26-2135-40ff-81b8-b113010403ec"
      },
      "outputs": [],
      "source": [
        "# ========================\n",
        "# 9. Eƒüitim Grafikleri\n",
        "# ========================\n",
        "plt.figure(figsize=(16,8))\n",
        "\n",
        "plt.subplot(2,3,1)\n",
        "plt.plot(history[\"epoch\"], history[\"train_loss\"], label=\"Train Loss\")\n",
        "plt.plot(history[\"epoch\"], history[\"val_loss\"], label=\"Val Loss\")\n",
        "plt.title(\"Loss\")\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(2,3,2)\n",
        "plt.plot(history[\"epoch\"], history[\"train_acc\"], label=\"Train Acc\")\n",
        "plt.plot(history[\"epoch\"], history[\"val_acc\"], label=\"Val Acc\")\n",
        "plt.title(\"Accuracy (%)\")\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(2,3,3)\n",
        "plt.plot(history[\"epoch\"], history[\"val_dice\"], label=\"Val Dice\")\n",
        "plt.title(\"Validation Dice Score\")\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(2,3,4)\n",
        "plt.plot(history[\"epoch\"], history[\"val_iou\"], label=\"Val IoU\")\n",
        "plt.title(\"Validation IoU Score\")\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(2,3,5)\n",
        "plt.plot(history[\"epoch\"], history[\"epoch_time_sec\"], label=\"Epoch Duration (s)\")\n",
        "plt.title(\"Epoch S√ºresi\")\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"training_plots.png\")\n",
        "plt.show()\n",
        "print(\"üìà Eƒüitim grafikleri 'model.png' olarak kaydedildi.\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7dae7166-0988-439a-a7da-b008efcb82de",
      "metadata": {
        "id": "7dae7166-0988-439a-a7da-b008efcb82de"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def f1_score_metric(pred, target, smooth=1e-6):\n",
        "    pred = pred.astype(np.float32)\n",
        "    target = target.astype(np.float32)\n",
        "    intersection = (pred * target).sum()\n",
        "    precision = intersection / (pred.sum() + smooth)\n",
        "    recall = intersection / (target.sum() + smooth)\n",
        "    f1 = 2 * precision * recall / (precision + recall + smooth)\n",
        "    return f1\n",
        "\n",
        "def voe_metric(pred, target):\n",
        "    # Volume Overlap Error = 1 - Jaccard index\n",
        "    intersection = np.logical_and(pred, target).sum()\n",
        "    union = np.logical_or(pred, target).sum()\n",
        "    jaccard = intersection / union if union != 0 else 1.0\n",
        "    voe = 1 - jaccard\n",
        "    return voe\n",
        "\n",
        "def mean_surface_distance(pred, target):\n",
        "    from scipy.spatial.distance import directed_hausdorff\n",
        "\n",
        "    pred_edges = np.argwhere(np.diff(pred.astype(np.uint8), axis=0) != 0)\n",
        "    target_edges = np.argwhere(np.diff(target.astype(np.uint8), axis=0) != 0)\n",
        "    if len(pred_edges) == 0 or len(target_edges) == 0:\n",
        "        return 0.0\n",
        "    d_pred_to_target = directed_hausdorff(pred_edges, target_edges)[0]\n",
        "    d_target_to_pred = directed_hausdorff(target_edges, pred_edges)[0]\n",
        "    msd = (d_pred_to_target + d_target_to_pred) / 2\n",
        "    return msd\n",
        "\n",
        "def compute_roc_auc(outputs, masks):\n",
        "    # Flattened arrays\n",
        "    outputs_flat = outputs.flatten()\n",
        "    masks_flat = masks.flatten()\n",
        "    try:\n",
        "        score = roc_auc_score(masks_flat, outputs_flat)\n",
        "    except:\n",
        "        score = float('nan')\n",
        "    return score\n",
        "\n",
        "def dice_coefficient(preds, targets, threshold=0.5):\n",
        "    preds = preds > threshold\n",
        "    intersection = np.sum(preds * targets)\n",
        "    return 2. * intersection / (np.sum(preds) + np.sum(targets) + 1e-8)\n",
        "\n",
        "def jaccard_index(preds, targets, threshold=0.5):\n",
        "    preds = preds > threshold\n",
        "    intersection = np.sum(preds * targets)\n",
        "    union = np.sum(preds) + np.sum(targets) - intersection\n",
        "    return intersection / (union + 1e-8)\n",
        "\n",
        "def precision(preds, targets, threshold=0.5):\n",
        "    preds = preds > threshold\n",
        "    true_positive = np.sum(preds * targets)\n",
        "    false_positive = np.sum(preds * (1 - targets))\n",
        "    return true_positive / (true_positive + false_positive + 1e-8)\n",
        "\n",
        "def recall(preds, targets, threshold=0.5):\n",
        "    preds = preds > threshold\n",
        "    true_positive = np.sum(preds * targets)\n",
        "    false_negative = np.sum((1 - preds) * targets)\n",
        "    return true_positive / (true_positive + false_negative + 1e-8)\n",
        "\n",
        "def specificity(preds, targets, threshold=0.5):\n",
        "    preds = preds > threshold\n",
        "    true_negative = np.sum((1 - preds) * (1 - targets))\n",
        "    false_positive = np.sum(preds * (1 - targets))\n",
        "    return true_negative / (true_negative + false_positive + 1e-8)\n",
        "\n",
        "def hausdorff_distance(preds, targets):\n",
        "    from scipy.spatial.distance import directed_hausdorff\n",
        "\n",
        "    pred_coords = np.array(np.where(preds == 1)).T\n",
        "    target_coords = np.array(np.where(targets == 1)).T\n",
        "\n",
        "    if len(pred_coords) == 0 or len(target_coords) == 0:\n",
        "        return 0\n",
        "\n",
        "    forward_hausdorff = directed_hausdorff(pred_coords, target_coords)[0]\n",
        "    backward_hausdorff = directed_hausdorff(target_coords, pred_coords)[0]\n",
        "    return max(forward_hausdorff, backward_hausdorff)\n",
        "\n",
        "def assd(preds, targets):\n",
        "    from scipy.spatial.distance import cdist\n",
        "\n",
        "    pred_coords = np.array(np.where(preds == 1)).T\n",
        "    target_coords = np.array(np.where(targets == 1)).T\n",
        "\n",
        "    if len(pred_coords) == 0 or len(target_coords) == 0:\n",
        "        return 0\n",
        "\n",
        "    dist_pred_to_target = cdist(pred_coords, target_coords)\n",
        "    dist_target_to_pred = cdist(target_coords, pred_coords)\n",
        "\n",
        "    assd_val = (np.mean(np.min(dist_pred_to_target, axis=1)) + np.mean(np.min(dist_target_to_pred, axis=1))) / 2\n",
        "    return assd_val\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3c616e9-5ede-47d8-bd25-ff5c87f98e9f",
      "metadata": {
        "id": "d3c616e9-5ede-47d8-bd25-ff5c87f98e9f"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import numpy as np\n",
        "from scipy.spatial.distance import directed_hausdorff, cdist\n",
        "from sklearn.metrics import roc_auc_score, f1_score\n",
        "\n",
        "def visualize_all_predictions(model, test_loader, device, save_dir=None):\n",
        "    model.eval()\n",
        "\n",
        "    all_test_dices = []\n",
        "    all_test_jaccards = []\n",
        "    all_test_precisions = []\n",
        "    all_test_recalls = []\n",
        "    all_test_specificities = []\n",
        "    all_test_hd = []\n",
        "    all_test_assd = []\n",
        "    all_test_roc_auc = []\n",
        "    all_test_voe = []\n",
        "    all_test_msd = []\n",
        "    all_test_f1 = []\n",
        "\n",
        "    if save_dir:\n",
        "        os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (images, masks) in enumerate(test_loader):\n",
        "            images = images.to(device)\n",
        "            masks = masks.to(device)\n",
        "            outputs = model(images)\n",
        "            probs = torch.sigmoid(outputs)\n",
        "            preds = (probs > 0.5).float()\n",
        "\n",
        "            preds_np = preds.cpu().numpy()\n",
        "            probs_np = probs.cpu().numpy()\n",
        "            masks_np = masks.cpu().numpy()\n",
        "\n",
        "            for i in range(images.size(0)):\n",
        "                image = images[i].cpu().permute(1, 2, 0).numpy()\n",
        "                mask = masks_np[i][0]\n",
        "                pred = preds_np[i][0]\n",
        "                prob = probs_np[i][0]\n",
        "\n",
        "                # üî¢ Sƒ±ralƒ± numara\n",
        "                sample_index = batch_idx * test_loader.batch_size + i\n",
        "\n",
        "                # üìä G√∂rselle≈ütirme\n",
        "                fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
        "                axs[0].imshow(image)\n",
        "                axs[0].set_title(\"Input Image\")\n",
        "                axs[0].axis(\"off\")\n",
        "\n",
        "                axs[1].imshow(mask, cmap='gray')\n",
        "                axs[1].set_title(\"Ground Truth Mask\")\n",
        "                axs[1].axis(\"off\")\n",
        "\n",
        "                axs[2].imshow(pred, cmap='gray')\n",
        "                axs[2].set_title(\"Predicted Mask\")\n",
        "                axs[2].axis(\"off\")\n",
        "\n",
        "                plt.tight_layout()\n",
        "\n",
        "                if save_dir:\n",
        "                    file_path = f\"{save_dir}/sample_{sample_index:04d}.png\"\n",
        "                    plt.savefig(file_path, dpi=150)\n",
        "                    print(f\"üìÅ Saved image to: {file_path}\")\n",
        "                    plt.close()\n",
        "                else:\n",
        "                    plt.show()\n",
        "                    plt.close()\n",
        "\n",
        "                # üßÆ Metrik hesaplama\n",
        "                dice = dice_coefficient(pred, mask)\n",
        "                jaccard = jaccard_index(pred, mask)\n",
        "                precision_value = precision(pred, mask)\n",
        "                recall_value = recall(pred, mask)\n",
        "                specificity_value = specificity(pred, mask)\n",
        "                hd_value = hausdorff_distance(pred, mask)\n",
        "                assd_value = assd(pred, mask)\n",
        "                voe = volume_overlap_error(pred, mask)\n",
        "                msd_value = mean_surface_distance(pred, mask)\n",
        "\n",
        "                try:\n",
        "                    f1 = f1_score(mask.flatten().astype(int), pred.flatten().astype(int))\n",
        "                except:\n",
        "                    f1 = np.nan\n",
        "\n",
        "                try:\n",
        "                    roc_auc = roc_auc_score(mask.flatten(), prob.flatten())\n",
        "                except ValueError:\n",
        "                    roc_auc = np.nan\n",
        "\n",
        "                print(f\"Sample {sample_index:04d} Metrics:\")\n",
        "                print(f\"DICE: {dice:.4f}\")\n",
        "                print(f\"Jaccard: {jaccard:.4f}\")\n",
        "                print(f\"Precision: {precision_value:.4f}\")\n",
        "                print(f\"Recall: {recall_value:.4f}\")\n",
        "                print(f\"Specificity: {specificity_value:.4f}\")\n",
        "                print(f\"Hausdorff Distance: {hd_value:.4f}\")\n",
        "                print(f\"ASSD: {assd_value:.4f}\")\n",
        "                print(f\"F1 Score: {f1:.4f}\")\n",
        "                print(f\"VOE (Volume Overlap Error): {voe:.4f}\")\n",
        "                print(f\"Mean Surface Distance (MSD): {msd_value:.4f}\")\n",
        "                print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
        "                print(\"-\" * 50)\n",
        "\n",
        "                # ‚è∫ Metriƒüi sakla\n",
        "                all_test_dices.append(dice)\n",
        "                all_test_jaccards.append(jaccard)\n",
        "                all_test_precisions.append(precision_value)\n",
        "                all_test_recalls.append(recall_value)\n",
        "                all_test_specificities.append(specificity_value)\n",
        "                all_test_hd.append(hd_value)\n",
        "                all_test_assd.append(assd_value)\n",
        "                all_test_f1.append(f1)\n",
        "                all_test_voe.append(voe)\n",
        "                all_test_msd.append(msd_value)\n",
        "                all_test_roc_auc.append(roc_auc)\n",
        "\n",
        "    # üìä Ortalama metrikler\n",
        "    print(f\"\\nüìà Average Test Metrics (Overall):\")\n",
        "    print(f\"DICE: {np.nanmean(all_test_dices):.4f}\")\n",
        "    print(f\"Jaccard: {np.nanmean(all_test_jaccards):.4f}\")\n",
        "    print(f\"Precision: {np.nanmean(all_test_precisions):.4f}\")\n",
        "    print(f\"Recall: {np.nanmean(all_test_recalls):.4f}\")\n",
        "    print(f\"Specificity: {np.nanmean(all_test_specificities):.4f}\")\n",
        "    print(f\"Hausdorff Distance: {np.nanmean(all_test_hd):.4f}\")\n",
        "    print(f\"ASSD: {np.nanmean(all_test_assd):.4f}\")\n",
        "    print(f\"F1 Score: {np.nanmean(all_test_f1):.4f}\")\n",
        "    print(f\"VOE: {np.nanmean(all_test_voe):.4f}\")\n",
        "    print(f\"Mean Surface Distance: {np.nanmean(all_test_msd):.4f}\")\n",
        "    print(f\"ROC-AUC: {np.nanmean(all_test_roc_auc):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e743667-a5fe-4375-ba79-8c2a55102e31",
      "metadata": {
        "id": "1e743667-a5fe-4375-ba79-8c2a55102e31"
      },
      "outputs": [],
      "source": [
        "save_dir = \"./model_predictions\"  # √áalƒ±≈üma dizininde klas√∂r olu≈üturur ve kaydeder\n",
        "visualize_all_predictions(model, test_loader, device, save_dir=save_dir)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94c09f95-0eb6-468a-94d9-6fde4b3e2384",
      "metadata": {
        "id": "94c09f95-0eb6-468a-94d9-6fde4b3e2384"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Torch",
      "language": "python",
      "name": "torch"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}